# syntax=docker/dockerfile:1
#
# ================================================
# | AUTISM CLASSIFICATION MODEL INFERENCE SERVER |
# ================================================
# 
# This Dockerfile is used to build model inference server for Autism Classification.
# 
# Quick Command to Build Inference Server
# =======================================
# docker build -t autism_classification:server -f Build_Server .
#
# Quick Command to Run inference Server
# =====================================
# docker run --rm -it --gpus all \
#     -v [ Required: Your Directory Containing Trained Resources ]:/resources \
#     -v [ Required: Your Path to Base Data Directory ]:/data \
#     autism_classification:server [ Your Arguments ]
#
# Main Build Script
# =================
#
# Pull pytorch/pytorch:1.12.1-cuda11.3-cudnn8-runtime Image from Docker-Hub
FROM pytorch/pytorch@sha256:0bc0971dc8ae319af610d493aced87df46255c9508a8b9e9bc365f11a56e7b75
# Install Necessary Packages
RUN pip3 install --no-cache-dir flask==2.2.2
# Copy Resources to Respective Directories
RUN mkdir /data
RUN mkdir /resources
RUN mkdir -p /root/.cache/torch/hub/checkpoints/
COPY ./Resources/resnet50-11ad3fa6.pth /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth
WORKDIR /workspace
# Copy Trainer Files for Execution
COPY ./Server/inference_server.py ./inference_server.py
# Copy Model File
COPY ./model.py ./model.py
# Set Permissions & Create Execution Entrypoint
RUN chmod 777 ./inference_server.py
ENTRYPOINT [ "./inference_server.py" ]
